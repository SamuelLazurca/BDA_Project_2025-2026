{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507495ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, NGram, SQLTransformer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon_Reviews_Recommender_Optimized\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"2g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2000\") \\\n",
    "    .config(\"spark.default.parallelism\", \"2000\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.6\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1024m\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77ad0a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "PARQUET_PATH = \"reviews_final_parquet\"\n",
    "df = spark.read.parquet(PARQUET_PATH)\n",
    "\n",
    "df_spark = df.withColumn(\n",
    "    \"label\", \n",
    "    F.when((F.col(\"overall\") >= 1) & (F.col(\"overall\") <= 2.5), 0.0)\n",
    "     .when((F.col(\"overall\") > 2.5) & (F.col(\"overall\") <= 3.5), 1.0)\n",
    "     .otherwise(2.0)\n",
    ")\n",
    "\n",
    "ngram = NGram(n=2, inputCol=\"lemmatized_tokens\", outputCol=\"bigrams\")\n",
    "\n",
    "combiner = SQLTransformer(\n",
    "    statement=\"SELECT *, concat(lemmatized_tokens, bigrams) AS all_tokens FROM __THIS__\"\n",
    ")\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"all_tokens\", outputCol=\"rawFeatures\", numFeatures=2**16)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# Multiclass Logistic Regression\n",
    "lr = LogisticRegression(\n",
    "    labelCol=\"label\", \n",
    "    featuresCol=\"features\", \n",
    "    maxIter=10, \n",
    "    regParam=0.01, \n",
    "    elasticNetParam=1.0, \n",
    "    family=\"multinomial\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[ngram, combiner, hashingTF, idf, lr])\n",
    "\n",
    "train_df, test_df = df_spark.randomSplit([0.9, 0.1], seed=42)\n",
    "\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1-score: {f1:.4f}\")\n",
    "\n",
    "model_path = \"logreg_sentiment_pipeline_v2\"\n",
    "print(f\"--- Saving PipelineModel to {model_path} ---\")\n",
    "\n",
    "model.write().save(model_path)\n",
    "print(\"Success: Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40b052",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test Accuracy: 0.8377\n",
    "Test F1-score: 0.7740\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
