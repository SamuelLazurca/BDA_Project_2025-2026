{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3b68a9-65ff-4711-87ab-afbef8edd0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/16 00:57:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/01/16 00:57:22 WARN SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory 'checkpoints_als' appears to be on the local filesystem.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Filtering Data ---\n",
      "--- Indexing column: reviewerID ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Indexing column: asin ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Joining Indices back to Data ---\n",
      "--- Splitting Data ---\n",
      "--- Persisting to Disk (Not RAM) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Count: 60149963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Count: 15036389\n",
      "--- Calculating User Means ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training ALS ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Trained Successfully ---\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 326:====================================================>(736 + 6) / 744]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.027357238789061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon_Reviews_Recommender_Optimized\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"2g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2000\") \\\n",
    "    .config(\"spark.default.parallelism\", \"2000\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.6\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1024m\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setCheckpointDir(\"checkpoints_als\")\n",
    "\n",
    "PARQUET_PATH = \"reviews_final_parquet\"\n",
    "df = spark.read.parquet(PARQUET_PATH)\n",
    "\n",
    "def load_and_clean_data(df):\n",
    "    item_counts = df.groupBy(\"asin\").count().filter(F.col(\"count\") >= 5)\n",
    "    user_counts = df.groupBy(\"reviewerID\").count().filter(F.col(\"count\") >= 5)\n",
    "    \n",
    "    df_clean = df.join(item_counts, \"asin\", \"left_semi\") \\\n",
    "                 .join(user_counts, \"reviewerID\", \"left_semi\")\n",
    "    return df_clean\n",
    "\n",
    "print(\"--- Filtering Data ---\")\n",
    "df_spark = load_and_clean_data(df)\n",
    "\n",
    "\n",
    "def create_index_mapping(df, col_name, output_col):\n",
    "    print(f\"--- Indexing column: {col_name} ---\")\n",
    "    distinct_vals = df.select(col_name).distinct()\n",
    "    \n",
    "    mapping_rdd = distinct_vals.rdd.map(lambda r: r[0]).zipWithUniqueId()\n",
    "    \n",
    "    mapping_df = spark.createDataFrame(mapping_rdd, schema=[\"original_id\", \"numeric_id\"])\n",
    "    \n",
    "    mapping_path = f\"mappings/{col_name}_mapping\"\n",
    "    mapping_df.write.mode(\"overwrite\").parquet(mapping_path)\n",
    "    \n",
    "    return spark.read.parquet(mapping_path).withColumnRenamed(\"original_id\", col_name).withColumnRenamed(\"numeric_id\", output_col)\n",
    "\n",
    "user_mapping = create_index_mapping(df_spark, \"reviewerID\", \"user_id_index\")\n",
    "item_mapping = create_index_mapping(df_spark, \"asin\", \"asin_index\")\n",
    "\n",
    "print(\"--- Joining Indices back to Data ---\")\n",
    "df_indexed = df_spark.join(user_mapping, on=\"reviewerID\", how=\"inner\") \\\n",
    "                     .join(item_mapping, on=\"asin\", how=\"inner\")\n",
    "\n",
    "df_final = df_indexed.select(\n",
    "    F.col(\"user_id_index\").cast(\"integer\"),\n",
    "    F.col(\"asin_index\").cast(\"integer\"),\n",
    "    F.col(\"overall\").cast(\"float\")\n",
    ")\n",
    "\n",
    "print(\"--- Splitting Data ---\")\n",
    "(training_data, test_data) = df_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "training_data.persist(StorageLevel.DISK_ONLY)\n",
    "test_data.persist(StorageLevel.DISK_ONLY)\n",
    "\n",
    "print(f\"Training Count: {training_data.count()}\")\n",
    "print(f\"Test Count: {test_data.count()}\")\n",
    "\n",
    "print(\"--- Calculating User Means ---\")\n",
    "user_means = training_data.groupBy(\"user_id_index\") \\\n",
    "    .agg(F.avg(\"overall\").alias(\"user_mean\"))\n",
    "\n",
    "training_centered = training_data.join(user_means, on=\"user_id_index\", how=\"inner\")\n",
    "training_centered = training_centered.withColumn(\"centered_rating\", F.col(\"overall\") - F.col(\"user_mean\"))\n",
    "\n",
    "training_centered_path = \"tmp_training_centered\"\n",
    "training_centered.write.mode(\"overwrite\").parquet(training_centered_path)\n",
    "training_centered_ready = spark.read.parquet(training_centered_path)\n",
    "\n",
    "print(\"--- Training ALS ---\")\n",
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    "    rank=10, \n",
    "    userCol=\"user_id_index\",\n",
    "    itemCol=\"asin_index\",\n",
    "    ratingCol=\"centered_rating\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=False,\n",
    "    checkpointInterval=2  \n",
    ")\n",
    "\n",
    "model = als.fit(training_centered_ready)\n",
    "print(\"--- Model Trained Successfully ---\")\n",
    "\n",
    "print(\"--- Evaluating ---\")\n",
    "test_with_mean = test_data.join(user_means, on=\"user_id_index\", how=\"inner\")\n",
    "predictions = model.transform(test_with_mean)\n",
    "\n",
    "final_predictions = predictions.withColumn(\n",
    "    \"final_prediction\", \n",
    "    F.col(\"prediction\") + F.col(\"user_mean\")\n",
    ")\n",
    "\n",
    "final_predictions = final_predictions.withColumn(\n",
    "    \"final_prediction_clipped\", \n",
    "    F.when(F.col(\"final_prediction\") > 5, 5.0)\n",
    "     .when(F.col(\"final_prediction\") < 1, 1.0)\n",
    "     .otherwise(F.col(\"final_prediction\"))\n",
    ")\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"overall\", \n",
    "    predictionCol=\"final_prediction_clipped\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(final_predictions)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc0f2f-b409-410e-992b-817a403f0cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading model from als_recommender_model_v1 ---\n",
      "Success: Model loaded.\n",
      "--- Verifying Loaded Model on Test Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-------+----------+-----------------+-----------------------+\n",
      "|user_id_index|asin_index|overall|prediction|        user_mean|final_prediction_loaded|\n",
      "+-------------+----------+-------+----------+-----------------+-----------------------+\n",
      "|      3472753|       496|    5.0|-0.5912889|3.945945945945946|      3.354657021728722|\n",
      "|       792285|       496|    5.0|-0.5473409|              4.0|     3.4526590704917908|\n",
      "|      1415638|       496|    5.0|  0.709856|4.461038961038961|      5.170894934759511|\n",
      "|      1730055|       496|    5.0|-0.6964582|              3.2|     2.5035417795181276|\n",
      "|       351178|       496|    5.0| 0.4956245|4.441860465116279|      4.937484977550285|\n",
      "+-------------+----------+-------+----------+-----------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 955:====================================================>(734 + 6) / 744]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0393701316582167\n",
      "Verification complete. Generated predictions for 15033986 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "\n",
    "# --- 1. Save the Model ---\n",
    "model_path = \"als_recommender_model_v1\"\n",
    "# print(f\"--- Saving model to {model_path} ---\")\n",
    "model.write().overwrite().save(model_path)\n",
    "print(\"Success: Model saved.\")\n",
    "\n",
    "print(f\"--- Loading model from {model_path} ---\")\n",
    "loaded_model = ALSModel.load(model_path)\n",
    "print(\"Success: Model loaded.\")\n",
    "\n",
    "print(\"--- Verifying Loaded Model on Test Data ---\")\n",
    "\n",
    "predictions_from_loaded = loaded_model.transform(test_with_mean)\n",
    "\n",
    "# De-Centering logic\n",
    "final_check = predictions_from_loaded.withColumn(\n",
    "    \"final_prediction_loaded\", \n",
    "    F.col(\"prediction\") + F.col(\"user_mean\")\n",
    ")\n",
    "\n",
    "final_check.select(\n",
    "    \"user_id_index\", \n",
    "    \"asin_index\", \n",
    "    \"overall\", \n",
    "    \"prediction\", \n",
    "    \"user_mean\",\n",
    "    \"final_prediction_loaded\"\n",
    ").show(5)\n",
    "\n",
    "count = final_check.count()\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"overall\", \n",
    "    predictionCol=\"final_prediction_loaded\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(final_check)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Verification complete. Generated predictions for {count} rows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
